# Code Explained

This document breaks down the project structure and explains the role of each major file and directory.

## Project Structure

```
meyme-ai-voice-agent/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ code_explained.md
â”‚   â”œâ”€â”€ prd.md
â”‚   â””â”€â”€ resources.md
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ stt.py
â”‚   â””â”€â”€ tts.py
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ script.js
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ .env
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## File & Directory Breakdown

### ğŸ“„ `main.py`
This is the heart of the backend application. It's a FastAPI server with three primary responsibilities:
1.  **Serving the Frontend:** It serves the `index.html` file at the root URL (`/`).
2.  **Health Check:** Provides a `/health` endpoint to check the status of downstream AI services.
3.  **WebSocket Handling:** Manages the main `/ws` endpoint for the real-time conversational loop. This is where the core orchestration happens: receiving audio, calling the STT, LLM, and TTS services, and streaming the response back to the client.

### ğŸ“ `docs/`
This directory contains all the detailed documentation for the project.
- `architecture.md`: Explains the system architecture and the rationale behind the streaming workflow.
- `code_explained.md`: This file.
- `prd.md`: The Product Requirements Document, outlining the vision and features.
- `resources.md`: A day-by-day list of tasks and resources from the challenge.

### ğŸ“ `services/`
This directory contains modules that abstract the interactions with third-party AI services, keeping the main application logic clean and organized.
- `stt.py`: Handles everything related to Speech-to-Text. It contains the logic for making streaming transcription requests to AssemblyAI.
- `llm.py`: Manages the connection to the Large Language Model (Google Gemini). It takes the transcribed text and generates a personality-driven, streaming response.
- `tts.py`: Responsible for Text-to-Speech. It takes the streaming response from the LLM and streams it to Murf AI to generate the final audio.

### ğŸ“ `static/`
This directory holds all the static assets for the frontend.
- `script.js`: The core frontend logic. It handles audio recording (`MediaRecorder`), WebSocket communication with the backend, and playback of the streaming audio response. It also manages UI state and animations.
- `style.css`: Contains all the styling for the `index.html` page, including the modern glassmorphic design, animations, and responsive layout.

### ğŸ“ `templates/`
This directory contains the HTML templates served by FastAPI.
- `index.html`: The single-page frontend for the application. It defines the structure of the UI, including the record button and audio visualization elements.

### ğŸ“„ `.env`
This file stores the secret API keys for AssemblyAI, Google Gemini, and Murf AI. It is loaded at startup and is crucial for the application to function. It is listed in `.gitignore` to prevent it from being committed to version control.

### ğŸ“„ `README.md`
This is the main entry point for understanding the project. It contains a high-level overview, demo links, a feature list, and setup instructions.

### ğŸ“„ `requirements.txt`
This file lists all the Python dependencies required to run the backend server (e.g., `fastapi`, `uvicorn`, `python-dotenv`, `assemblyai`).
